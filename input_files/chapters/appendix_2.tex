\chapter{Annexes du chapitre 3}\label{annexe-2}
\dochaptoc

    \section{L'estimateur de Stein et la régression isotonique}\label{abstr-regression-isotonique}
    
    Dans le chapitre~\ref{ch-chapter_3}, la méthode \gls{3s} a été présentée afin de résoudre le problème de reconstruction d'un spectre-image spatialement sous-échantillonné. Cette technique s'appuie sur l'estimation de poids $(w_m)_{m=1,\dots,\gls{M}}$ dont l'expression a été déterminée à la \cref{subsec-3s-poids} en se basant sur une analyse bayésienne. Or, cette expression requiert les valeurs propres $(\tilde{d}^2_m)_{m=1,\dots,\gls{M}}$ associées aux composantes principales des observations \gls{Yi}, qui ne peuvent être évaluées avec fiabilité puisque le nombre d'échantillons \gls{N} est du même ordre de grandeur que la dimension des données \gls{M}. C'est pourquoi l'estimateur de Stein a été proposé à la \cref{subsec-3s-acp} afin de corriger les estimées issues de l'\gls{acp} $(\tilde{d}_m)_{m=1,\dots,\gls{M}}$. Seulement, les valeurs corrigées par l'estimateur de Stein ne conservent ni la positivité, ni la propriété de non-croissance propres aux estimées $(\tilde{d}_m)_{m}$. Cette constatation a motivé l'usage d'une régression isotonique comme post-traitement dans~\cite{LinPerl1985} afin de restituer ces deux propriétés primordiales dans la construction des poids. Cette stratégie est détaillée dans ce qui suit et la procédure comme l'exemple sont issus de~\cite{LinPerl1985}.
    
    D'abord, il convient de simplifier les notations en notant les estimées de Stein corrigées et celles issues de l'\gls{acp} $\varphi_m$ et $d_m$ respectivement\footnote{Ces notations ne sont propres qu'à cette section uniquement.}. A la suite de l'équation~\eqref{eq-Stein-corr}, l'estimateur de Stein (avant correction) se réécrit donc $d_m/\alpha_m$ où $\alpha_m$ dépend de $d_m$ et constitue le dénominateur de l'expression~\eqref{eq-Stein-corr}. Afin de faciliter la discussion, nous allons disposer les $d_m$ en colonne et les $\alpha_m$ à côté comme suit
    \begin{equation}
    \begin{matrix}
    d_1&\alpha_1\\
    d_2&\alpha_2\\
    d_3&\alpha_1\\
    \vdots&\vdots\\
    d_{\gls{M}}&\alpha_{\gls{M}}\\
    \end{matrix}
    \end{equation}
    Notons d'ailleurs que l'estimateur de Stein avant correction s'obtient en faisant le rapport de la première colonne par la deuxième
    \begin{equation}
    \begin{matrix}
    d_1&\alpha_1&d_1/\alpha_1\\
    d_2&\alpha_2&d_2/\alpha_2\\
    d_3&\alpha_1&d_3/\alpha_3\\
    \vdots&\vdots&\vdots\\
    d_{\gls{M}}&\alpha_{\gls{M}}&d_{\gls{M}}/\alpha_{\gls{M}}\\
    \end{matrix}
    \end{equation}
    Dès lors, la correction s'effectue en trois étapes successives visant à corriger les estimées de Stein afin de restituer les propriétés de positivité et de décroissance désirées.
    
    \bigskip\noindent%
    \textbf{Etape 1 :} Rendre les $\alpha_m$ positifs.
    \begin{enumerate}[label={(\alph*)}]
        \item Commencer en bas de la liste et remonter jusqu'à atteindre la première paire, notons-la $(d_m, \alpha_m)$, dont la valeur $\alpha_m$ est négative.\label{sein-iso-1-1}
        \item Fusionner cette paire avec la paire immédiatement supérieure, en les remplaçant avec la paire $(d_m + d_{m-1}, \alpha_m + \alpha_{m-1})$, afin de former une liste d'une paire plus courte que la précédente.\label{sein-iso-1-2}
        \item Répéter les étapes~\ref{sein-iso-1-1} et~\ref{sein-iso-1-2} pour la nouvelle liste jusqu'à avoir tous les $\alpha_m$ positifs.
    \end{enumerate}
    
    \bigskip\noindent%
    \textbf{Etape 2 :} Ré-ordonner les rapports $d_m/\alpha_m$ jusqu'à ce qu'ils soient ordonnés par ordre décroissant.
    
    Lister tous les rapports $d_m/\alpha_m$ à la droite de chaque paire $(d_m, \alpha_m)$ obtenus de l'étape 1. Une paire $(d_m, \alpha_m)$ (à l'exception de la paire située en bas de la liste) est appelée \emph{erronée} si le ratio $d_m/\alpha_m$ n'est pas supérieur au ratio $d_{m+1}/\alpha_{m-1m+1}$.
    \begin{enumerate}[label={(\alph*)}]
        \item Commencer en bas de la liste obtenue de l'étape 1 et remonter la liste jusqu'à ce que la première paire erronée, notons-la $(d_m, \alpha_m)$, soit atteinte.
        \item Fusionner cette paire erronée avec la paire immédiatement inférieure en remplaçant ces paires et leur ratio par la paire $(d_m + d_{m+1},\alpha_m + \alpha_{m-1m+1})$ et le ratio $(d_m + d_{m+1})/(\alpha_m + \alpha_{m+1})$. La liste obtenue est donc d'une paire plus courte.\label{sein-iso-2-2}
        \item Continuer à la paire immédiatement en dessous de la paire modifiée issue de l'étape~\ref{sein-iso-2-2} (ou la paire modifiée elle-même s'il s'agit de la paire en bas de la liste) et remonter jusqu'à atteindre la première paire erronée, puis répéter l'étape~\ref{sein-iso-2-2}.\label{sein-iso-2-3}
        \item Répéter l'étape~\ref{sein-iso-2-2} jusqu'à ce que tous les rapports $d_m/\alpha_m$ soient ordonnés par ordre décroissant.
    \end{enumerate}
    Si les calculs sont effectués à la main, l'étape 2 peut être simplifiée en fusionnant tout bloc de deux paires consécutives ou plus de la liste dont les rapports correspondants ne sont pas triés par ordre décroissant.
    
    \bigskip\noindent%
    \textbf{Etape 3 :} Chacun des rapports présents dans la liste finale a été obtenu en fusionnant un bloc d'une ou plusieurs paires consécutives $(d_m,\alpha_m)$ issues de la liste initiale. Pour obtenir les estimées de Stein corrigées, on assigne ce rapport à toutes les paires du bloc.
    
    \bigskip\noindent%
    \textbf{Exemple :} Un exemple est donné à la \tabname~\ref{tab-stein-corr-example} afin d'illustrer les trois étapes détaillées ci-dessus. Une matrice aléatoire $\mathbf{A}$ de taille $10\times 10$ dont les éléments sont des réalisations d'une variable aléatoire gaussienne centrée réduite est générée. Les valeurs propres $d_m$ de $\mathbf{A}^T\mathbf{A}$ et les valeurs $\alpha_m$ ont été calculées et sont affichées sur les colonnes de gauche. Puisque $\alpha_6$ est négatif, les deux colonnes suivantes, \ie\ la nouvelle liste de paires $(d_m, \alpha_m)$, sont obtenus lors de la première étape en fusionnant les paires $(d_5, \alpha_5)$ et $(d_6,\alpha_6)$ de la liste originale. Pour améliorer la lisibilité, les paires n'étant pas modifiées par l'étape~1 n'ont pas été réécrites dans la nouvelle liste. Lors de l'étape~2, la première colonne liste les rapports $d_m/\alpha_m$ correspondants aux paires $(d_m, \alpha_m)$ issues de la première étape. Puisque les quatre rapports du haut ne sont pas triés par ordre décroissant, les quatre paires correspondantes sont fusionnées afin d'obtenir le nouveau rapport \np{11.96}. La nouvelle liste de rapports, \ie{} la seconde colonne de l'étape 2, est maintenant dans l'ordre décroissant, donc aucune nouvelle fusion n'est nécessaire. Dans l'étape 3, nous assignons simplement chaque rapport issu de l'étape 2 à l'ensemble des paires qui ont été fusionnées au cours des deux premières étapes afin d'obtenir ce rapport.
    
    
    
    
    \begin{table*}[]
        \centering
        \begin{tabular}{crrcllc}
            \toprule
            &\multicolumn{3}{c}{\textbf{Etape 1}}& \multicolumn{2}{c}{\textbf{Etape 2}}&\textbf{Etape 3}\\
            indice&\multicolumn{2}{c}{$(d_m, \alpha_m)$}&$(d_m, \alpha_m)$&$d_m/\alpha_m$&$d_m/\alpha_m$&$\varphi_m$\\
            \midrule
            1&32.03&	3.15&&10.17&\rdelim\}{4}{*}[\parbox{1cm}{\centering 11.96}]&11.96\\
            2&24.42&	2.30&&10.62&&11.96\\
            3&19.42&	1.21&&16.05&&11.96\\
            4&13.95&	0.85&&16.41&&11.96\\
            5&7.33&	2.70&\rdelim\}{2}{*}[\parbox{2.5cm}{\centering 13.96\quad 1.53}]&\multirow{2}{*}{9.12}&&9.12\\
            6&6.63&	$-$1.17&&&&9.12\\
            7&3.01&	0.45&&6.69&&6.69\\
            8&1.35&	0.28&&4.82&&4.82\\
            9&0.35&	0.33&\rdelim\}{2}{*}[\parbox{2.5cm}{\centering 0.50\quad 0.22}]&\multirow{2}{*}{2.27}&&2.27\\
            10&0.15&	$-$0.11&&&&2.27\\
            \bottomrule
        \end{tabular}
        \vspace{1em}
        \caption{Exemple illustrant les étapes 1 à 3.
            \protect\label{tab-stein-corr-example}}
    \end{table*} 
    

    \section{Implémentation pratique des méthodes S2N et 3S}\label{annexe-implementation-3s-s2n}

    \'A la section~\ref{ch-3-implementation}, l'implémentation des méthodes S2N et 3S a été détaillée en se basant sur l'algorithme FISTA. Si le codage de la méthode S2N reste facile pour un jeu de paramètres fixe, cela devient plus compliqué pour 3S qui nécessite de nombreuses étapes. De plus, la méthode détaillée à la section~\ref{sec-s2n-param-tuning} permettant d'obtenir une estimation des paramètres de régularisation optimaux n'est pas triviale à implémenter. Dans cette section, l'implémentation pratique des méthodes est donc détaillée.

    \subsection{Implémentation sans recherche de paramètre}

    Dans le cas où les paramètres de régularisation sont fixés, la méthode S2N s'implémente facilement à l'aide de l'algorithme FISTA (\cf\ algorithme~\ref{algo-FISTA}) pour donner l'algorithme~\ref{algo-S2N-sans-param}. La méthode 3S, quant à elle, nécessite quelques étapes en prétraitement pour obtenir les données dans la base des composantes principales et estimer la dimension du sous-espace signal $R$, les puissances corrigées $\hat{d}_m^2$, le niveau de bruit $\hat{\sigma}^2$ et les poids $w_m$. L'algorithme~\ref{algo-3S-sans-param} résume l'ensemble de ces étapes et constitue un appui pour implémenter 3S. 

    \begin{normalalgorithme*}
        \begin{minipage}{\textwidth}
            \begin{algorithm}[H]
                \SetKwInOut{Input}{Entrée}
                \SetKwInOut{Output}{Sortie}
                \SetKwInOut{Init}{Initialisation}
                %
                \SetKwComment{Comment}{}{}
                %
                \Input{Observation $\gls{Y}_{\gls{I}}$, ensemble \gls{I}, paramètres $(\gls{ls2n}, \gls{ms2n})$}
                \Init{Fixer $\mathbf{Z}^{(1)} = \mathbf{W}^{(0)} = \mathbf{X}^{(0)} \in \mathbb{R}^{M\times P}$, $\theta^{(1)}=1$, $i=1$, $L=1+8\gls{ls2n}$}
                %
                \medskip
                \While{critère d'arrêt n'est pas satisfait}{
                    %
                    $\mathbf{W}^{(i)} = \mathbf{Z}^{(i)} -\frac{1}{L} \left\{ (\mathbf{Z}^{(i)}\gls{Phi} - \gls{Yi})\gls{Phi}^T - \gls{ls2n} \mathbf{Z}^{(i)} \Delta \right\}$\;
                    %
                    Calcul de la SVD de $\mathbf{W}^{(i)} = \mathbf{U\boldsymbol\Sigma V}^T$ avec $\boldsymbol\Sigma = \mathrm{diag}(\mu_i)$\;
                    %
                    Calcul des $\bar{\mu}_i = \mathrm{sgn}(\mu_i)\left(|\mu_i|-\frac{\gls{ms2n}}{L}\right)\iota_{\mu_i>\gls{ms2n}}(\mu_i)$\;
                    %
                    $\mathbf{X}^{(i)} = \mathbf{U\bar{\boldsymbol\Sigma} V}^T$ avec $\bar{\boldsymbol\Sigma} = \mathrm{diag}(\bar{\mu}_i)$\;
                    %
                    $\theta^{(i+1)} = \frac{1}{2} \left(1+\sqrt{1+4(\theta^{(i)})^2}\right)$\;
                    %
                    $\mathbf{Z}^{(i+1)} = \mathbf{X}^{(i)} + \left( \frac{\theta^{(i)}-1}{\theta^{(i+1)}} \right) \left(\mathbf{X}^{(i)}-\mathbf{X}^{(i-1)} \right)$\;
                    %
                    $i \leftarrow i+1$
                }
                %
                \medskip
                \Output{$\gls{Xh}(\lambda, \mu) = \gls{X}^{(i-1)}$}
            \end{algorithm}
        \end{minipage}
        \caption{S2N sans recherche de paramètres.\protect\label{algo-S2N-sans-param}}
    \end{normalalgorithme*}



    \begin{normalalgorithme*}
        \begin{minipage}{\textwidth}
            \begin{algorithm}[H]
                \SetKwInOut{Input}{Entrée}
                \SetKwInOut{Output}{Sortie}
                \SetKwInOut{Init}{Initialisation}
                %
                \SetKwComment{Comment}{}{}
                %
                \Input{Observation $\gls{Y}_{\gls{I}}$, ensemble \gls{I}, paramètre \gls{m3s}}
                
                %
                \medskip
                Appliquer une ACP à $\gls{Y}_{\gls{I}}$ et obtenir la base \gls{H} des composantes principales et les valeurs propres empiriques $\tilde{d}_m^2$\;
                %
                Corriger les valeurs propres empiriques (estimateur de Stein) $\rightarrow$ $\hat{d}_m^2 = \frac{\tilde{d}^2_m}{1+ \frac{1}{N}\sum_{\substack{j=1\\j\neq m }}^M \frac{\tilde{d}^2_m+\tilde{d}^2_j}{\tilde{d}^2_m-\tilde{d}^2_j}}$\;
                %
                Estimer la dimension $R = \argmax_m {m}$ tel que $\hat{d}_m^2 > \hat{d}_M^2$ et le niveau de bruit $\hat{\sigma}^2 = \hat{d}_M^2$\;

                Calcul des poids $w_m = \frac{\gls{hsig}^2}{\hat{d}_m^2 - \gls{hsig}^2}$\;

                \medskip

                \Init{Fixer $\mathbf{Z}^{(1)} = \mathbf{W}^{(0)} = \mathbf{S}^{(0)} \in \mathbb{R}^{R\times P}$, $\theta^{(1)}=1$, $i=1$, $L=8+\gls{m3s} \max_m\{w_m\}$}

                \medskip

                \While{critère d'arrêt n'est pas satisfait}{
                    %
                    $\mathbf{W}^{(i)} = \mathbf{Z}^{(i)} -\frac{1}{L} \left\{ -\frac{1}{\gls{R}} \gls{S}\Delta + \gls{m3s}\mathbf{W}\gls{S} \right\}$\;

                    \For{$p = 1$ \KwTo $P$}{
                        \If{$p\in\mathcal{I}$ et $||\mathbf{w}^{(i)}_p - \gls{H}^T\mathbf{y}_p|| > \sqrt{R}\hat{\sigma}$}{
                            %
                            $\mathbf{s}^{(i)}_p = \sqrt{R}\hat{\sigma} \frac{\mathbf{w}^{(i)}_p - \gls{H}^T\mathbf{y}_p}{||\mathbf{w}^{(i)}_p - \gls{H}^T\mathbf{y}_p||}$
                        }
                        \Else{
                            $\mathbf{s}^{(i)}_p = \mathbf{w}^{(i)}_p$
                        }
                    }
                    %
                    $\theta^{(i+1)} = \frac{1}{2} \left(1+\sqrt{1+4(\theta^{(i)})^2}\right)$\;
                    %
                    $\mathbf{Z}^{(i+1)} = \mathbf{S}^{(i)} + \left( \frac{\theta^{(i)}-1}{\theta^{(i+1)}} \right) \left(\mathbf{S}^{(i)}-\mathbf{S}^{(i-1)} \right)$\;
                    %
                    $i \leftarrow i+1$
                }
                %
                \medskip
                \Output{$\gls{Xh}(\mu) = \gls{H}\gls{S}^{(i-1)}$}
            \end{algorithm}
        \end{minipage}
        \caption{3S sans recherche de paramètres.\protect\label{algo-3S-sans-param}}
    \end{normalalgorithme*}


    \subsection{Estimation des paramètres de régularisation optimaux}

    \'A la section~\ref{sec-s2n-param-tuning}, nous avons présenté une méthode d'estimation des paramètres de régularisation maximisant la qualité de reconstruction. Celle-ci consiste à minimiser la fonction
\begin{equation}
\mathcal{J}\left(\lambda,\mu\right) \triangleq \left(\frac{1}{\gls{M}\gls{N}}\left\|\gls{Yi}-\gls{Xh}_{\gls{I}}{(\lambda,\mu)}\right\|_{\mathrm{F}}^2-\hat{\gls{sig}}^2\right)^2
\end{equation}
relativement à $\lambda$ d'abord, puis par rapport à $\mu$, et enfin par rapport à un facteur d'échelle $c$. Une façon plus commode d'implémenter cette méthode consiste non pas à minimiser $\mathcal{J}$, mais plutôt à déterminer le zéro de la fonction
\begin{equation}
\mathcal{J}'\left(\lambda,\mu\right) \triangleq \frac{1}{\gls{M}\gls{N}}\left\|\gls{Yi}-\gls{Xh}_{\gls{I}}{(\lambda,\mu)}\right\|_{\mathrm{F}}^2-\hat{\gls{sig}}^2.
\end{equation}
En effet, pour un paramètre de régularisation nul, le terme $\frac{1}{\gls{M}\gls{N}}\left\|\gls{Yi}-\gls{Xh}_{\gls{I}}{(\lambda,\mu)}\right\|_{\mathrm{F}}^2$ s'annule tandis qu'il s'approche de la puissance du signal pour un paramètre infini.

L'implémentation de cette méthode s'est faite par dichotomie. Par exemple, le zéro de $\mathcal{J}'\left(\cdot,0\right)$ a été obtenu à partir d'un segment de recherche initial $[\lambda_{\mathrm{min}}^{(0)}, \lambda_{\mathrm{max}}^{(0)}]$ mis à jour au fur et à mesure des itérations en fonction du signe du centre du segment courant. Ainsi, la recherche des paramètres optimaux pour la méthode S2N correspond à l'algorithme~\ref{algo-S2N-avec-param}. L'application à 3S détaillé à l'algorithme~\ref{algo-3S-avec-param} est plus aisée puisque seul un paramètre est à estimer.





    \begin{normalalgorithme*}
        \begin{minipage}{\textwidth}
            \begin{algorithm}[H]
                \SetKwInOut{Input}{Entrée}
                \SetKwInOut{Output}{Sortie}
                \SetKwInOut{Init}{Initialisation}
                %
                \SetKwComment{Comment}{}{}
                %
                \Input{Observation $\gls{Y}_{\gls{I}}$, ensemble \gls{I}, %
                segments $[\lambda_{\mathrm{min}}^{(0)}, \lambda_{\mathrm{max}}^{(0)}]$,
                $[\mu_{\mathrm{min}}^{(0)}, \mu_{\mathrm{max}}^{(0)}]$ et 
                $[c_{\mathrm{min}}^{(0)}, c_{\mathrm{max}}^{(0)}]$}
                %
                
                \medskip
                \Comment{Estimation de $\lambda^{\circ}$} 

                $\gls{Xh}(\lambda_{\mathrm{min}}^{(0)}, 0) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (\lambda_{\mathrm{min}}^{(0)}, 0)\}$ et 
                $\gls{Xh}(\lambda_{\mathrm{max}}^{(0)}, 0) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (\lambda_{\mathrm{max}}^{(0)}, 0)\}$\;
                i = 0\;

                %
                \medskip
                \While{critère d'arrêt n'est pas satisfait}{
                    %
                    $\lambda_{\mathrm{mean}}^{(i)} = \frac{1}{2}(\lambda_{\mathrm{min}}^{(i)} + \lambda_{\mathrm{max}}^{(i)})$\;
                    %
                    $\gls{Xh}(\lambda_{\mathrm{mean}}^{(i)}, 0) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (\lambda_{\mathrm{mean}}^{(i)}, 0)\}$\;
                    %
                    \If{$\mathcal{J}'\left(\lambda_{\mathrm{mean}}^{(i)},0 \right) > 0$}{
                        $\lambda_{\mathrm{max}}^{(i+1)} =  \lambda_{\mathrm{mean}}^{(i)}$\;
                    }
                    \Else{
                        $\lambda_{\mathrm{min}}^{(i+1)} =  \lambda_{\mathrm{mean}}^{(i)}$\;
                    }
                    $i = i+1$ \;
                }
                $\lambda^{\circ} = \frac{1}{2}(\gls{Xh}(\lambda_{\mathrm{min}}^{(i-1)} + \lambda_{\mathrm{max}}^{(i-1)})$

                \medskip
                \Comment{Estimation de $\mu^{\circ}$} 

                $\gls{Xh}(0, \mu_{\mathrm{min}}^{(0)}) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (0, \mu_{\mathrm{min}}^{(0)})\}$ et 
                $\gls{Xh}(0, \mu_{\mathrm{max}}^{(0)}) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (0, \mu_{\mathrm{max}}^{(0)})\}$\;
                i = 0\;

                \While{critère d'arrêt n'est pas satisfait}{
                    %
                    $\mu_{\mathrm{mean}}^{(i)} = \frac{1}{2}(\mu_{\mathrm{min}}^{(i)} + \mu_{\mathrm{max}}^{(i)})$\;
                    %
                    $\gls{Xh}(0, \mu_{\mathrm{mean}}^{(i)}) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (0, \mu_{\mathrm{mean}}^{(i)})\}$\;
                    %
                    \If{$\mathcal{J}'\left(0, \mu_{\mathrm{mean}}^{(i)} \right) > 0$}{
                        $\mu_{\mathrm{max}}^{(i+1)} =  \mu_{\mathrm{mean}}^{(i)}$\;
                    }
                    \Else{
                        $\mu_{\mathrm{min}}^{(i+1)} =  \mu_{\mathrm{mean}}^{(i)}$\;
                    }
                    $i = i+1$ \;
                }
                $\mu^{\circ} = \frac{1}{2}(\gls{Xh}(\mu_{\mathrm{min}}^{(i-1)} + \mu_{\mathrm{max}}^{(i-1)})$

                \medskip
                \Comment{Estimation de $c^{\circ}$} 

                $\gls{Xh}(c_{\mathrm{min}}^{(0)}\lambda^{\circ}, c_{\mathrm{min}}^{(0)}\mu^{\circ}) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (c_{\mathrm{min}}^{(0)}\lambda^{\circ}, c_{\mathrm{min}}^{(0)}\mu^{\circ})\}$ et 
                $\gls{Xh}(c_{\mathrm{max}}^{(0)}\lambda^{\circ}, c_{\mathrm{max}}^{(0)}\mu^{\circ}) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, (c_{\mathrm{max}}^{(0)}\lambda^{\circ}, c_{\mathrm{max}}^{(0)}\mu^{\circ})\}$\;
                i = 0\;

                \While{critère d'arrêt n'est pas satisfait}{
                    %
                    $c_{\mathrm{mean}}^{(i)} = \frac{1}{2}(c_{\mathrm{min}}^{(i)} + c_{\mathrm{max}}^{(i)})$\;
                    
                    $\gls{Xh}(
                    c_{\mathrm{mean}}^{(i)}\lambda^{\circ}, c_{\mathrm{mean}}^{(i)}\mu^{\circ}
                    ) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, 
                    (c_{\mathrm{mean}}^{(i)}\lambda^{\circ}, c_{\mathrm{mean}}^{(i)}\mu^{\circ})
                    \}$\;
                    %
                    \If{
                        $\mathcal{J}'\left(c_{\mathrm{mean}}^{(i)}\lambda^{\circ}, c_{\mathrm{mean}}^{(i)}\mu^{\circ} \right) > 0$
                    }{
                       $c_{\mathrm{max}}^{(i+1)} =  c_{\mathrm{mean}}^{(i)}$\;
                    }
                    \Else{
                        $c_{\mathrm{min}}^{(i+1)} =  c_{\mathrm{mean}}^{(i)}$\;
                    }
                    $i = i+1$ \;
                }
                $c^{\circ} = \frac{1}{2}(c_{\mathrm{min}}^{(i-1)} + c_{\mathrm{max}}^{(i-1)})$

                %
                \medskip
                \Output{$\gls{Xh}(c^{\circ}\lambda^{\circ}, c^{\circ}\mu^{\circ})$}
            \end{algorithm}
        \end{minipage}
        \caption{S2N avec recherche de paramètres.\protect\label{algo-S2N-avec-param}}
    \end{normalalgorithme*}

    \begin{normalalgorithme*}
        \begin{minipage}{\textwidth}
            \begin{algorithm}[H]
                \SetKwInOut{Input}{Entrée}
                \SetKwInOut{Output}{Sortie}
                \SetKwInOut{Init}{Initialisation}
                %
                \SetKwComment{Comment}{}{}
                %
                \Input{Observation $\gls{Y}_{\gls{I}}$, ensemble \gls{I}, %
                segments $[\mu_{\mathrm{min}}^{(0)}, \mu_{\mathrm{max}}^{(0)}]$}
                %
                
                \medskip

                $\gls{Xh}(\mu_{\mathrm{min}}^{(0)}) = \mathrm{3S}\{\gls{Y}_{\gls{I}}, \gls{I}, \mu_{\mathrm{min}}^{(0)}\}$ et 
                $\gls{Xh}(\mu_{\mathrm{max}}^{(0)}) = \mathrm{S2N}\{\gls{Y}_{\gls{I}}, \gls{I}, \mu_{\mathrm{max}}^{(0)}\}$\;
                i = 0\;

                \While{critère d'arrêt n'est pas satisfait}{
                    %
                    $\mu_{\mathrm{mean}}^{(i)} = \frac{1}{2}(\mu_{\mathrm{min}}^{(i)} + \mu_{\mathrm{max}}^{(i)})$\;
                    %
                    $\gls{Xh}(\mu_{\mathrm{mean}}^{(i)}) = \mathrm{3S}\{\gls{Y}_{\gls{I}}, \gls{I}, (\mu_{\mathrm{mean}}^{(i)})\}$\;
                    %
                    \If{$\frac{1}{\gls{M}\gls{N}}\left\|\gls{Yi}-\gls{Xh}_{\gls{I}}{(\mu_{\mathrm{mean}}^{(i)})}\right\|_{\mathrm{F}}^2-\hat{\gls{sig}}^2>0$}{
                        $\mu_{\mathrm{max}}^{(i+1)} =  \mu_{\mathrm{mean}}^{(i)}$\;
                    }
                    \Else{
                        $\mu_{\mathrm{min}}^{(i+1)} =  \mu_{\mathrm{mean}}^{(i)}$\;
                    }
                    $i = i+1$ \;
                }
                $\mu^{\circ} = \frac{1}{2}(\gls{Xh}(\mu_{\mathrm{min}}^{(i-1)} + \mu_{\mathrm{max}}^{(i-1)})$

                %
                \medskip
                \Output{$\gls{Xh}(\mu^{\circ})$}
            \end{algorithm}
        \end{minipage}
        \caption{3S avec recherche de paramètres.\protect\label{algo-3S-avec-param}}
    \end{normalalgorithme*}
    